{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "670a94c4-70fb-4ad4-9a09-88a8d1d823c2",
   "metadata": {},
   "source": [
    "## Synthetic pair generation (new)\n",
    "Create **brand-new** valid-ish levels, corrupt them, and export JSONL pairs for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ceac94-3f60-4297-94b7-adc5d50d26c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, random\n",
    "from pathlib import Path\n",
    "\n",
    "random.seed(17)\n",
    "\n",
    "# ---------------- Config ----------------\n",
    "N_TRAIN, N_VAL = 200, 40\n",
    "W, H = 64, 16\n",
    "OUT_DIR = Path(\"data\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUT_TRAIN = OUT_DIR / \"train_pairs.jsonl\"\n",
    "OUT_VAL   = OUT_DIR / \"val_pairs.jsonl\"\n",
    "\n",
    "# Token vocabulary\n",
    "VOCAB = ['M','F','y','Y','E','g','G','k','K','r','X','#','%','|','*','B','b','?','@','Q','!','1','2','D','S','C','U','L','o','t','T','<','>','[',']']\n",
    "BACKGROUND = '|'\n",
    "\n",
    "def blank_level():\n",
    "    return [[BACKGROUND for _ in range(W)] for _ in range(H)]\n",
    "\n",
    "def add_ground(level, min_h=1):\n",
    "    for y in range(H-1, H-1-min_h, -1):\n",
    "        for x in range(W):\n",
    "            level[y][x] = 'X'\n",
    "\n",
    "def add_platforms(level, n=8):\n",
    "    import random\n",
    "    for _ in range(n):\n",
    "        y = random.randint(5, H-4)\n",
    "        x0 = random.randint(2, W-8)\n",
    "        length = random.randint(3, 8)\n",
    "        for x in range(x0, min(W-1, x0+length)):\n",
    "            level[y][x] = 'S'\n",
    "\n",
    "def add_coins(level, n=60):\n",
    "    import random\n",
    "    for _ in range(n):\n",
    "        x = random.randint(1, W-2)\n",
    "        y = random.randint(3, H-5)\n",
    "        if level[y][x] == BACKGROUND:\n",
    "            level[y][x] = 'o'\n",
    "\n",
    "def add_enemies(level, n=20):\n",
    "    import random\n",
    "    for _ in range(n):\n",
    "        x = random.randint(2, W-3)\n",
    "        y = H-2\n",
    "        while y > 1 and level[y+1][x] == BACKGROUND:\n",
    "            y += 1\n",
    "        if level[y][x] in (BACKGROUND, 'o'):\n",
    "            level[y][x] = random.choice(['E','g','G','k','K','r'])\n",
    "\n",
    "def add_pipe(level):\n",
    "    import random\n",
    "    x0 = random.randint(6, W-8)\n",
    "    ground_y = H-2\n",
    "    ph = random.randint(2, 4)\n",
    "    for dy in range(ph):\n",
    "        level[ground_y - dy][x0]   = '['\n",
    "        level[ground_y - dy][x0+1] = ']'\n",
    "    level[ground_y - ph][x0]   = '<'\n",
    "    level[ground_y - ph][x0+1] = '>'\n",
    "    if random.random() < 0.2:\n",
    "        level[ground_y - ph - 1][x0] = 'T'\n",
    "\n",
    "def place_M_and_F(level):\n",
    "    import random\n",
    "    mx = random.randint(1, 4)\n",
    "    my = H-2\n",
    "    while my > 0 and level[my+1][mx] == BACKGROUND:\n",
    "        my += 1\n",
    "    level[my][mx] = 'M'\n",
    "    fx = random.randint(W-6, W-3)\n",
    "    fy = H-2\n",
    "    while fy > 0 and level[fy+1][fx] == BACKGROUND:\n",
    "        fy += 1\n",
    "    level[fy][fx] = 'F'\n",
    "\n",
    "def gen_clean_level():\n",
    "    lvl = blank_level()\n",
    "    add_ground(lvl, min_h=1)\n",
    "    add_platforms(lvl, n=random.randint(6, 10))\n",
    "    add_coins(lvl, n=random.randint(40, 80))\n",
    "    add_enemies(lvl, n=random.randint(10, 25))\n",
    "    for _ in range(random.randint(1, 3)):\n",
    "        add_pipe(lvl)\n",
    "    place_M_and_F(lvl)\n",
    "    return lvl\n",
    "\n",
    "def flatten_tokens(level):\n",
    "    return \" \".join(level[y][x] for y in range(H) for x in range(W))\n",
    "\n",
    "def corrupt_tokens(tokens, drop_p=0.02, flip_p=0.05, insert_p=0.01, remove_M_prob=0.25, remove_F_prob=0.20):\n",
    "    import random\n",
    "    out = []\n",
    "    for t in tokens:\n",
    "        r = random.random()\n",
    "        if t == 'M' and random.random() < remove_M_prob:\n",
    "            continue\n",
    "        if t == 'F' and random.random() < remove_F_prob:\n",
    "            continue\n",
    "        if r < drop_p:\n",
    "            continue\n",
    "        elif r < drop_p + flip_p:\n",
    "            out.append(random.choice(VOCAB))\n",
    "        else:\n",
    "            out.append(t)\n",
    "            if random.random() < insert_p:\n",
    "                out.append(random.choice(VOCAB))\n",
    "    return out or tokens\n",
    "\n",
    "def gen_pair():\n",
    "    clean = gen_clean_level()\n",
    "    clean_tokens = flatten_tokens(clean).split()\n",
    "    corrupted = corrupt_tokens(clean_tokens)\n",
    "    return \" \".join(corrupted), \" \".join(clean_tokens)\n",
    "\n",
    "def write_pairs(n, path):\n",
    "    with path.open(\"w\") as f:\n",
    "        for _ in range(n):\n",
    "            corr, clean = gen_pair()\n",
    "            f.write(json.dumps({\"corrupted\": corr, \"repaired\": clean}) + \"\\n\")\n",
    "    print(f\"Wrote {n} pairs -> {path}\")\n",
    "\n",
    "write_pairs(N_TRAIN, OUT_TRAIN)\n",
    "write_pairs(N_VAL,   OUT_VAL)\n",
    "print(\"Synthetic pair generation complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e411f23",
   "metadata": {},
   "source": [
    "## Training (compat)\n",
    "Version-adaptive training cell that works across older/newer `transformers` installs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335314e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xhepon\\anaconda3\\envs\\rp_mario\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers version: 4.56.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|█████████████████████████████████████████████████████████████████████| 40/40 [00:00<00:00, 686.08 examples/s]\n",
      "C:\\Users\\xhepon\\anaconda3\\envs\\rp_mario\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  2/150 : < :, Epoch 0.02/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForCausalLM,\n",
    "    TrainingArguments, Trainer, DataCollatorForLanguageModeling,\n",
    "    __version__ as TR_VER\n",
    ")\n",
    "from inspect import signature\n",
    "\n",
    "print(\"Transformers version:\", TR_VER)\n",
    "\n",
    "MODEL_NAME = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "OUTPUT_DIR = \"out/llm-sft-pairs-compat\"\n",
    "\n",
    "train_file = \"data/train_pairs.jsonl\"\n",
    "val_file   = \"data/val_pairs.jsonl\"\n",
    "\n",
    "INSTR_FIELD = \"corrupted\"\n",
    "RESP_FIELD  = \"repaired\"\n",
    "BLOCK_SIZE  = 512\n",
    "BATCH_TOKENS = 4096\n",
    "\n",
    "def to_text(example):\n",
    "    instr = str(example[INSTR_FIELD]).strip()\n",
    "    resp  = str(example[RESP_FIELD]).strip()\n",
    "    example[\"text\"] = f\"<s>Instruction:\\\\n{instr}\\\\n\\\\nResponse:\\\\n{resp}</s>\"\n",
    "    return example\n",
    "\n",
    "train_ds = load_dataset(\"json\", data_files=train_file, split=\"train\").map(to_text)\n",
    "val_ds   = load_dataset(\"json\", data_files=val_file,   split=\"train\").map(to_text)\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "if tok.pad_token is None:\n",
    "    tok.pad_token = tok.eos_token\n",
    "\n",
    "def tok_fn(examples):\n",
    "    return tok(examples[\"text\"], truncation=True, max_length=BLOCK_SIZE)\n",
    "\n",
    "train_tok = train_ds.map(tok_fn, batched=True, remove_columns=[\"text\"])\n",
    "val_tok   = val_ds.map(tok_fn,   batched=True, remove_columns=[\"text\"])\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n",
    "collator = DataCollatorForLanguageModeling(tokenizer=tok, mlm=False)\n",
    "\n",
    "per_device_train_batch_size = 1\n",
    "gradient_accumulation_steps = max(1, BATCH_TOKENS // (per_device_train_batch_size * BLOCK_SIZE))\n",
    "per_device_eval_batch_size  = 1\n",
    "\n",
    "sig = signature(TrainingArguments.__init__).parameters\n",
    "def supports(name): return name in sig\n",
    "\n",
    "kwargs = dict(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-5,\n",
    "    warmup_steps=200,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50,\n",
    "    save_steps=1000,\n",
    "    eval_steps=500,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "# Batch size args (per_device vs per_gpu)\n",
    "if supports(\"per_device_train_batch_size\"):\n",
    "    kwargs[\"per_device_train_batch_size\"] = per_device_train_batch_size\n",
    "    kwargs[\"per_device_eval_batch_size\"] = per_device_eval_batch_size\n",
    "elif supports(\"per_gpu_train_batch_size\"):\n",
    "    kwargs[\"per_gpu_train_batch_size\"] = per_device_train_batch_size\n",
    "    if supports(\"per_gpu_eval_batch_size\"):\n",
    "        kwargs[\"per_gpu_eval_batch_size\"] = per_device_eval_batch_size\n",
    "\n",
    "# Scheduler + reporting\n",
    "if supports(\"lr_scheduler_type\"): kwargs[\"lr_scheduler_type\"] = \"cosine\"\n",
    "if supports(\"save_total_limit\"):  kwargs[\"save_total_limit\"] = 2\n",
    "if supports(\"report_to\"):         kwargs[\"report_to\"] = \"none\"\n",
    "\n",
    "# Evaluation control\n",
    "set_eval_after = False\n",
    "if supports(\"evaluation_strategy\"):\n",
    "    kwargs[\"evaluation_strategy\"] = \"steps\"\n",
    "elif supports(\"evaluate_during_training\"):\n",
    "    kwargs[\"evaluate_during_training\"] = True\n",
    "else:\n",
    "    # We'll evaluate explicitly after training\n",
    "    set_eval_after = True\n",
    "\n",
    "# Save strategy if available\n",
    "if supports(\"save_strategy\"):\n",
    "    kwargs[\"save_strategy\"] = \"steps\"\n",
    "\n",
    "args = TrainingArguments(**kwargs)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    data_collator=collator,\n",
    "    train_dataset=train_tok,\n",
    "    eval_dataset=val_tok,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "if set_eval_after:\n",
    "    print(\"Running post-hoc evaluation (no evaluation_strategy supported by this version)...\")\n",
    "    metrics = trainer.evaluate(eval_dataset=val_tok)\n",
    "    print(\"Eval metrics:\", metrics)\n",
    "\n",
    "trainer.save_model(OUTPUT_DIR)\n",
    "tok.save_pretrained(OUTPUT_DIR)\n",
    "\n",
    "print(\"Training (compat) finished. Saved to:\", OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fb9bdb-8bc5-46c1-a0a1-8964673c6ab4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rp_mario)",
   "language": "python",
   "name": "rp_mario"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
